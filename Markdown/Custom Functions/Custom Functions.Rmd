---
title: "Custom Functions"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
  word_document: null
---

```{r, include=F}
knitr::opts_chunk$set(echo = T,
                      eval = T,
                      cache = F,
                      message = F,
                      warning = F)

HOME <- "C:/Users/Owner/OneDrive/Thesis/Thesis R Project"
DERIVED <- file.path(HOME, "Derived")
MODELS <- file.path(DERIVED, "Models")
WORKSPACES <- file.path(DERIVED, "WORKSPACES")
EXPORT <- file.path(HOME, "Export")


library(PAA)
library(limma)
library(knitr)
library(doParallel)
library(Hmisc)
library(e1071)
library(randomForest)
library(kernlab)
library(caret)
library(dplyr)
library(reshape2)
library(ggplot2)
```

# Data Preparation
```{r loadGPR_withSpotQuality}
loadGPR_withSpotQuality <- 
  function (gpr.path = NULL, 
            targets.path = NULL, 
            array.type = "ProtoArray", 
            protoarray.aggregation = "min",
            array.columns = list(E = "F635 Median", 
                                 Eb = "B635 Median"), 
            array.annotation = c("Block", 
                                 "Column", 
                                 "Row", 
                                 "Description", 
                                 "Name", 
                                 "ID"),
            array.spotQuality = c("F635 % Sat.", 
                                  "SNR 635"))
  {
    if (is.null(gpr.path) || is.null(targets.path)) {
      stop("ERROR: Not all mandatory arguments have been defined!")
    }
    # PAA function to get sample meta data
    metaData.samples <- readTargets(targets.path)
    
    # Limma function to read in .gpr files
    elist <- read.maimages(files = metaData.samples, 
                           path = gpr.path, 
                           source = "genepix.median", 
                           columns = array.columns, 
                           annotation = array.annotation,
                           other.columns = array.spotQuality)
    # Cleaning
    elist$genes$Name <- make.names(elist$genes$Name)
    elist$genes$ID <- make.names(elist$genes$ID)
    elist$genes$ID <- gsub(pattern = "\\w+\\.",
                           replacement = "",
                           x = elist$genes$ID,
                           perl = T)
    
    metaData.samples$ArrayID <- make.names(metaData.samples$ArrayID)
    rownames(metaData.samples) <- NULL
    
    colnames(elist$E) <- metaData.samples$ArrayID
    colnames(elist$Eb) <- metaData.samples$ArrayID
    
    rownames(elist$E) <- elist$genes$ID
    rownames(elist$Eb) <- elist$genes$ID
    
    # Remove any features with Empty Descriptions
    if (any(grep("Empty", 
                 elist$genes$Description))) {
      elist <- elist[-grep("Empty", 
                           elist$genes$Description), 
                     ]
    }
    # Separate autoantigens from controls
    elist.data <- elist[-grep("Control", 
                              elist$genes$Description), ]
    
    elist.controls <- elist[grep("Control",
                                 elist$genes$Description), ]
    
    # Only control features with IgG in their name
    elist.controls <- elist.controls[grep("IgG",
                                          elist.controls$genes$Name), ]
    
    # Aggregate duplicate autoantigens into single expression values (minimum or mean)
    if (array.type == "ProtoArray" && protoarray.aggregation == "min") {
      row.len <- nrow(elist.data$E)
      col.len <- ncol(elist.data$E)
      tmp.col.len <- (row.len * col.len)/2
      elist.data$E[row(elist.data$E)[, 1]%%2 == 1] <- 
        elist.data$E %>%
        matrix(2, 
               tmp.col.len) %>%
        apply(2, min) %>%
        matrix(row.len/2,
               col.len)
      elist.data <- 
        elist.data[-row(elist.data)[, 1]%%2 == 1, ]
    }
    else if (array.type == "ProtoArray" && protoarray.aggregation == "mean") {
      elist.data$E[row(elist.data$E)[, 1]%%2 == 1, ] <- 
        (elist.data$E[row(elist.data$E)[, 1]%%2 == 1, ] 
         + elist.data$E[row(elist.data$E)[, 1]%%2 == 0, ]) / 2
      elist.data <- 
        elist.data[-row(elist.data)[, 1]%%2 == 1, ]
    }
    # Aggregate duplicate controls into single expression values (minimum or mean)
    if (array.type == "ProtoArray" && protoarray.aggregation == "min") {
      row.len <- nrow(elist.controls$E)
      col.len <- ncol(elist.controls$E)
      tmp.col.len <- (row.len * col.len) / 2
      elist.controls$E[row(elist.controls$E)[, 1]%%2 == 1] <- 
        elist.controls$E %>%
        matrix(2, 
               tmp.col.len) %>%
        apply(2, min) %>%
        matrix(row.len/2,
               col.len)
      
      elist.controls <- 
        elist.controls[-row(elist.controls)[, 1]%%2 == 1, ]
    }
    else if (array.type == "ProtoArray" && protoarray.aggregation == "mean") {
      elist.controls$E[row(elist.controls$E)[, 1]%%2 == 1, ] <- 
        (elist.controls$E[row(elist.controls$E)[, 1]%%2 == 1, ]
         + elist.controls$E[row(elist.controls$E)[, 1]%%2 == 0, ]) / 2
      elist.controls <- 
        
        elist.controls[-row(elist.controls)[, 1]%%2 == 1, ]
    }
    # Return
    elists <- list(elist.data = elist.data,
                   elist.controls = elist.controls,
                   metaData.samples = metaData.samples)
    return(elists)
  }
```

# Plotting
## plot.MA
Creates an MA plot for a particular sample in a melted dataset.
```{r plot.MA}
plot.MA <- function(data.melted, 
                    array,
                    value.var,
                    need.to.log2 = F){
  if (need.to.log2 == T){
    data.melted[, value.var] <- log2(data.melted[, value.var])
  }
  
  median.array <-
    data.melted %>%
    filter(Sample != array) %>%
    group_by(Feature)
  
  median.array <-
    eval(substitute(summarize(median.array,
                              median.value = median(value.var)),
                    list(value.var = as.name(value.var))))
  
  plotData <-
    data.melted %>%
    filter(Sample == array) %>%
    inner_join(median.array,
               by = "Feature")
  plotData <-
    eval(substitute(mutate(plotData,
                           M = value.var - median.value,
                           A = (value.var + median.value)/2),
                    list(value.var = as.name(value.var))))
  plotData %>%
    ggplot(aes(x = A,
               y = M)) +
    geom_point(alpha = .3) +
    geom_smooth() +
    geom_hline(yintercept = 0,
               color = "red",
               linetype = "dashed") +
    theme_bw() +
    ggtitle(array) +
    theme(title = element_text(face = "bold"),
          plot.title = element_text(size = 12),
          axis.title = element_text(size = 12),
          axis.text = element_text(size = 10))
}
```

## computeROC
```{r, computeROC}
# df has 2 columns: pred (prediction probabilities) and act (target class)
computeROC <- function(df, 
                       cost_of_fp = 1, 
                       cost_of_fn = 1, 
                       n=100) {
  class.neg <- levels(df$act)[1]
  class.pos <- levels(df$act)[2]
  
  tpr <- function(df, threshold) {
    sum(df$pred >= threshold & df$act == class.pos) / 
      sum(df$act == class.pos)
  }
  
  fpr <- function(df, threshold) {
    sum(df$pred >= threshold & df$act == class.neg) / 
      sum(df$act == class.neg)
  }
  
  cost <- function(df, threshold, cost.of.fp, cost.of.fn) {
    sum(df$pred >= threshold & df$act == class.neg) * cost_of_fp + 
      sum(df$pred < threshold & df$act == class.pos) * cost_of_fn
  }
  
  roc <- 
    data_frame(threshold = seq(0,1,length.out=n),
               tpr = sapply(threshold, 
                            function(x) tpr(df, x)),
               fpr = sapply(threshold, 
                            function(x) fpr(df, x)),
               cost = sapply(threshold, 
                             function(x) cost(df, 
                                              x, 
                                              cost_of_fp, 
                                              cost_of_fn))
    ) %>%
    arrange(desc(threshold))
  return(roc)
}
```

## plots.roc
```{r, plots.roc}
plots.roc <- function(roc, 
                      decision.threshold = .5, 
                      model){
  library(gridExtra)
  library(cowplot)
  
  # Find index of roc$threshold closest to decision threshold
  diffs.threshold <- roc$threshold - decision.threshold
  idx.threshold <- diffs.threshold %>%
    abs() %>%
    which.min()
  
  # TPR and FPR at that threshold
  tpr.threshold <- 
    roc[idx.threshold, "tpr"] %>%
    unlist()
  fpr.threshold <-
    roc[idx.threshold, "fpr"] %>%
    unlist()
  
  # plot.roc
  plot.roc <- roc %>%
    ggplot(aes(x = fpr,
               y = tpr)) +
    geom_path() +
    geom_abline(aes(xintercept = 0, 
                    yintercept = 0),
                slope = 1,
                alpha = .3,
                linetype = "dashed") +
    geom_point(aes(x = fpr.threshold,
                   y = tpr.threshold),
               color = "red",
               size = 2) +
    geom_hline(yintercept = tpr.threshold,
               color = "red",
               linetype = "dashed",
               alpha = .5) +
    geom_vline(xintercept = fpr.threshold,
               color = "red",
               linetype = "dashed",
               alpha = .5) +
    coord_fixed(xlim = c(0,1),
                ylim = c(0,1)) +
    xlab("FPR") +
    ylab("TPR") +
    ggtitle("ROC Curve") +
    theme_bw() +
    theme(axis.title = element_text(face = "bold"),
          panel.grid.minor = element_blank(),
          panel.grid.major = element_blank())
  
  # plot.threshold
  plot.threshold <- roc %>%
    ggplot(aes(threshold, 
               cost)) +
    geom_path() +
    geom_vline(xintercept = decision.threshold,
               alpha = .5,
               linetype = "dashed",
               color = "red") +
    geom_point(aes(x = decision.threshold,
                   y = roc$cost[idx.threshold]),
               size = 2,
               color = "red") +
    theme_bw() +
    ggtitle("Threshold Performance") +
    ylab("# Misclassifications") +
    xlab("Threshold") +
    theme(axis.title = element_text(face = "bold"))
  
  plot_grid(plot.roc,
            plot.threshold,
            align = "h")
}
```

# Train and RFE
## General functions
Caret prediction with progress tracking
```{r}
caretPred <- function (object, x) 
{
  df <- data.frame(size = length(colnames(object$trainingData)) - 1,
                   fitTime = object$times[[1]][3],
                   bestTune = object$bestTune)
  write.table(df, file = "Progress Tracker.txt",
              append = T,
              sep = "\t",
              col.names = F,
              row.names = F)
  
  tmp <- predict(object, x)
  if (object$modelType == "Classification" & !is.null(object$modelInfo$prob)) {
    out <- cbind(data.frame(pred = tmp), 
                 as.data.frame(predict(object, 
                                       x, type = "prob")))
  }
  else out <- tmp
  out
}
```

Custom summary function (AUC, accuracy, kappa, sensitivity, and specificity)
```{r}
summary.fiveStats <- function(data, lev = NULL, model = NULL) {
  class.neg <- levels(data$obs)[1]
  class.pos <- levels(data$obs)[2]
  
  tpr <- function(df, threshold) {
    sum(df[, class.pos] >= threshold & df$obs == class.pos) /
      sum(df$obs == class.pos)
  }
  
  fpr <- function(df, threshold) {
    sum(df[, class.pos] >= threshold & df$obs == class.neg) / 
      sum(df$obs == class.neg)
  }
  
  computeROC <- function(df, thresholds){
    roc <- data_frame(threshold = seq(1, 0,
                                      length.out = thresholds),
                      tpr = sapply(threshold, 
                                   function(x) tpr(df, x)),
                      fpr = sapply(threshold, 
                                   function(x) fpr(df, x)))
    return(roc)
  }
  
  roc.df <- computeROC(data, 1000)
  
  library(caTools)
  AUC <- trapz(roc.df$fpr, 
               roc.df$tpr)
  sens <- tpr(data, .5)
  spec <- 1 - fpr(data, .5)
  out <- c("ROC" = AUC,
           defaultSummary(data),
           "Sens" = sens,
           "Spec" = spec)
  return(out)
}
```

Modify selectVar() for when feature re-ranking is used.
```{r}
selectVar.rerank <- function(y, size)
{
  library(dplyr)
  finalImp <- 
    dplyr::filter(y, Variables == size) %>%
    dplyr::select(c(Overall, var)) %>%
    group_by(var) %>%
    summarize(count = length(var)) %>%
    arrange(desc(count))
  as.character(finalImp$var[1:size])
}
```

## RF functions
Random forest prediction with progress tracking.
```{r rfPred}
rfPred <- function(object, x){
  df <- data.frame(size = length(object$forest$xlevels),
                   fitTime = ave(object$oob.times)[1])
  write.table(df, file = "Progress Tracker.txt",
              append = T,
              sep = "\t",
              col.names = F,
              row.names = F)
  tmp <- predict(object, x)
  if (is.factor(object$y)) {
    out <- cbind(data.frame(pred = tmp),
                 as.data.frame(predict(object, 
                                       x, type = "prob")))
  }
  else {
    out <- tmp}
  out
}
```

Modified RF fit.
```{r rfFit.rerank}
rfFit.rerank <- function (x, y, first, last, ...) 
{
  library(randomForest)
  randomForest(x, y, 
               importance = TRUE, 
               keep.inbag = TRUE, ...)
}
```

```{r rfFit, include=F, eval = F}
rfFit <- function (x, y, first, last, ...) 
{
  library(randomForest)
  randomForest(x, y, 
               importance = first, 
               keep.inbag = TRUE, ...)
}
```

RF variable ranking.
```{r rf.rank}
rf.rank <- function(object, x, y){
  library(magrittr)
  library(dplyr)
  vImp <- as.data.frame(importance(object))
  vImp$var <- rownames(vImp)
  rownames(vImp) <- NULL
  vImp <- 
    vImp %>%
    arrange(desc(MeanDecreaseAccuracy)) %>%
    mutate(Overall = MeanDecreaseAccuracy)
  vImp <- vImp[, c(5, 6, 1:4)]
  vImp
}
```

rf.functions
```{r rf.functions}
rf.functions <- rfFuncs
rf.functions$pred <- rfPred
rf.functions$fit <- rfFit.rerank
rf.functions$selectVar <- selectVar.rerank
rf.functions$rank <- rf.rank
rf.functions$summary <- summary.fiveStats
```

## SVM functions
SVM variable ranking.
```{r svmRank.old, include = F, eval = F}
svmRank.old <- function (object, x, y)
{
  w <- t(object$finalModel@coef[[1]] %*% object$finalModel@xmatrix[[1]])
  z <- abs(w) / sqrt(sum(w^2))
  ord <- order(z, 
               decreasing = TRUE)
  vimp <- data.frame(Overall=z[ord], 
                     var=dimnames(z)[[1]][ord])
  rownames(vimp) <- vimp$var
  vimp
}
```

```{r svmRank}
svmRank <- function(object, x, y){
  library(dplyr)
  w <- t(object$finalModel@coef[[1]] %*% object$finalModel@xmatrix[[1]])
  vimp <- as.data.frame(w)
  colnames(vimp)[1] <- "W"
  vimp$var <- rownames(vimp)
  rownames(vimp) <- NULL
  vimp <- vimp[, c(2,1)]
  vimp <-
    vimp %>%
    dplyr::mutate(Overall = W^2) %>%
    dplyr::arrange(desc(Overall)) %>%
    dplyr::select(var, Overall)
  vimp
}
```

```{r svm.functions}
svm.functions <- caretFuncs
svm.functions$pred <- caretPred
svm.functions$rank <- svmRank
svm.functions$selectVar <- selectVar.rerank
svm.functions$summary <- summary.fiveStats
```

# Save
```{r}
save.image(file = file.path(WORKSPACES,
                            "Custom Functions.RData"))
```

